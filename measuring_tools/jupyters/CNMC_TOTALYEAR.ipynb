{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com utilitzar això\n",
    "\n",
    "## Canviar les variables\n",
    "`comer = 'LERSA'`\n",
    "`PATH = '/home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/{comer}/'.format(comer=comer)`\n",
    "\n",
    "# Crear els següents directoris dins CNMC_TOTALYEAR\n",
    "- CLMAGS\n",
    "- CLMAG5AS\n",
    "- F1S\n",
    "\n",
    "#### Nota: Revisar tarifes 3.1 amb més de 30000V de tensió. Hauríen de portar el codi EB i no el tenim a l'agree_tensio, així que s'hauria de revisar. Si no en tenim cap, les 3.1 van a la columna de 1kV a 30kV. Revisar el mateix per les tarifes 6.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validador Hores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validador\n",
    "def val(n_hours, df, ):\n",
    "    for tarifa in ('21', '2A'):\n",
    "        if len(df[(df.agree_tarifa == tarifa) & (df.agree_dh == 'E1')]) != n_hours:\n",
    "            print('Tarifa no te totes les hores: {}'.format(tarifa))\n",
    "        if len(df[(df.agree_tarifa == tarifa) & (df.agree_dh == 'E2')]) != n_hours:\n",
    "            print('Tarifa no te totes les hores: {}'.format(tarifa))\n",
    "    print 'Ha acabat validacio'\n",
    "\n",
    "def val_clmag5a(n_hours, df_tmp):\n",
    "    tarifa = list(set(df_tmp.agree_tarifa))[0]\n",
    "    if tarifa == '2.0 DHS':\n",
    "        msg = ('Ha acabat validacio {}'.format(tarifa))\n",
    "        print msg\n",
    "        return True\n",
    "    if len(df_tmp) != n_hours:\n",
    "        msg = ('Tarifa {} no te totes les hores df: {} vs {}!!!!'.format(tarifa, len(df_tmp), n_hours)) \n",
    "        print msg\n",
    "        return False\n",
    "    else:\n",
    "        msg = ('Ha acabat validacio {}'.format(tarifa))\n",
    "        print msg\n",
    "        return True\n",
    "\n",
    "def val_f1(n_hours, df_tmp):\n",
    "    if len(df_tmp) != n_hours:\n",
    "        msg = ('Tarifa 61 no te totes les hores df: {} vs {}!!!!'.format(len(df_tmp), n_hours)) \n",
    "        print msg\n",
    "        return False\n",
    "    else:\n",
    "        msg = ('Ha acabat validacio {}'.format('61'))\n",
    "        print msg\n",
    "        return True\n",
    "    \n",
    "def val_clmag(n_hours, df):\n",
    "    for tarifa in ('3.0', ):\n",
    "        if len(df[(df.agree_tarifa == tarifa) & (df.dh == 'E3')]) != n_hours:\n",
    "            print('Tarifa no te totes les hores: {}'.format(tarifa))\n",
    "    print 'Ha acabat validacio'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netejar directori F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_only_last_version(file_type=None):\n",
    "    if not file_type:\n",
    "        file_type = 'F1'\n",
    "    if file_type == 'F1':\n",
    "        #Clean F1\n",
    "        base_path = '{}{}S/'.format(PATH, file_type)\n",
    "        data_files = []\n",
    "        for _file in os.listdir(base_path):\n",
    "            data_files.append({'filename': _file, 'sub_filename': _file[:-11], 'generation_date': _file[17:-2], 'version': _file[-1:]})\n",
    "        df_f1s = pd.DataFrame(data_files)\n",
    "        df_check = df_f1s.groupby(['sub_filename']).aggregate({'version': 'count'}).reset_index()\n",
    "        for dup in list(df_check[df_check['version'] != 1]['sub_filename']):\n",
    "            df_x = df_f1s[df_f1s.sub_filename == dup].sort_values(['generation_date', 'version'])\n",
    "            df_x = df_x.drop(df_x.index[len(df_x)-1])\n",
    "            for filename in list(df_x['filename']):\n",
    "                print('{}'.format(filename))\n",
    "                os.remove('{}{}'.format(base_path, filename))\n",
    "    elif file_type == 'CLMAG5A':\n",
    "        #Clean CLMAG5A\n",
    "        pass\n",
    "    elif file_type == 'CLMAG':\n",
    "        #Clean CLMAG\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dies: 365\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201801</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201802</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201803</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201804</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201805</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201806</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201807</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201808</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201809</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201810</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201811</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201812</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        version\n",
       "month          \n",
       "201801       31\n",
       "201802       28\n",
       "201803       31\n",
       "201804       30\n",
       "201805       31\n",
       "201806       30\n",
       "201807       31\n",
       "201808       31\n",
       "201809       30\n",
       "201810       31\n",
       "201811       30\n",
       "201812       31"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_totally_f1():\n",
    "    base_path = '{}{}S/'.format(PATH, 'F1')\n",
    "    data_files = []\n",
    "    for _file in os.listdir(base_path):\n",
    "        data_files.append({'filename': _file, 'sub_filename': _file[:-11], 'month': _file[8:-13], 'generation_date': _file[17:-2], 'version': _file[-1:]})\n",
    "    df_f1s = pd.DataFrame(data_files)\n",
    "    return df_f1s.groupby(['month']).aggregate({'version': 'count'})\n",
    "total_days = check_totally_f1()['version'].sum()\n",
    "print('Total dies: {}'.format(total_days))\n",
    "check_totally_f1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definició imports i funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from measuring_tools.parsers import parser\n",
    "from measuring_tools.skeleton_files import cols\n",
    "from measuring_tools.comparative_tools import check_clmag5as, totalizer\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "comer = 'BINEFAR'\n",
    "PATH = '/home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/{comer}/'.format(comer=comer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escriure fitxers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_excel(data_f, name_sheet):\n",
    "    from openpyxl import load_workbook\n",
    "    filename = '{}result/{}.xlsx'.format(PATH, 'TOTAL')\n",
    "    try:\n",
    "        book = load_workbook(filename)\n",
    "    except Exception:\n",
    "        writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "        data_f.to_excel(writer, name_sheet, index=False, columns=['agree_tarifa', 'timestamp', 'measure'])\n",
    "        writer.save()\n",
    "        return True\n",
    "        \n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl') \n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "    data_f.to_excel(writer, name_sheet, index=False, columns=['agree_tarifa', 'timestamp', 'measure'])\n",
    "\n",
    "    writer.save()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLMAG5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT DADES CLMAG5A\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201804_20180611.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201801_20180412.3\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201809_20181207.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201812_20190222.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201811_20190118.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201807_20180925.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201810_20181212.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201808_20181108.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201803_20180510.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201805_20180713.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201802_20180417.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAG5AS/CLMAG5A_0291_201806_20180926.1\n",
      "Ha acabat validacio 2.0 DHA\n",
      "Ha acabat validacio 2.1 DHA\n",
      "Ha acabat validacio 2.0 A\n",
      "Ha acabat validacio 2.1 A\n"
     ]
    }
   ],
   "source": [
    "# Llegim els CLMAG5AS\n",
    "df = pd.DataFrame(data={})\n",
    "base_path = '{}{}/'.format(PATH, 'CLMAG5AS')\n",
    "if len(os.listdir(base_path)) != 12:\n",
    "    print('FALTEN MESOS!')\n",
    "print('IMPORTANT DADES CLMAG5A')\n",
    "\n",
    "for _file in os.listdir(base_path):\n",
    "    path_clmag5a = base_path + _file\n",
    "    print('Reading... {}'.format(path_clmag5a))\n",
    "    df_tmp = parser.read_CLMAG5A(path_clmag5a)\n",
    "    if df.empty:\n",
    "        df = df_tmp\n",
    "    else:\n",
    "        df = df.append(df_tmp)\n",
    "\n",
    "# AGRUPEM PER TARIFA\n",
    "df_2tariff = df.groupby(['agree_tarifa', 'agree_dh', 'timestamp', 'estacio']).aggregate({'measure': 'sum'}).reset_index()\n",
    "df_2tariff.sort_values(['timestamp', 'agree_tarifa'])\n",
    "\n",
    "# Escrivim els fitxers, un per tarifa\n",
    "df_2tariff = df_2tariff.replace('21', '2.1')\n",
    "df_2tariff = df_2tariff.replace('2A', '2.0')\n",
    "df_2tariff['agree_tarifa'] = np.where(\n",
    "    (df_2tariff['agree_dh'] == 'E2'), df_2tariff['agree_tarifa'] + ' DHA', df_2tariff['agree_tarifa']\n",
    ")\n",
    "df_2tariff['agree_tarifa'] = np.where(\n",
    "    (df_2tariff['agree_dh'] == 'E3'), df_2tariff['agree_tarifa'] + ' DHS', df_2tariff['agree_tarifa']\n",
    ")\n",
    "df_2tariff['agree_tarifa'] = np.where(\n",
    "    (df_2tariff['agree_dh'] == 'E1'), df_2tariff['agree_tarifa'] + ' A', df_2tariff['agree_tarifa']\n",
    ")\n",
    "\n",
    "tariffs = list(set(df_2tariff.agree_tarifa))\n",
    "for tariff in tariffs:\n",
    "    df_tariff = df_2tariff[df_2tariff.agree_tarifa == tariff]\n",
    "    if val_clmag5a(8760, df_tariff):\n",
    "        write_excel(df_tariff, str(tariff))\n",
    "        df_tariff.to_csv('{}result/{}.csv'.format(PATH, tariff), columns=['timestamp', 'measure', 'agree_tarifa'], sep=';', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLMAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201801_20180323.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201812_20190222.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201808_20181108.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201809_20181207.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201811_20190118.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201803_20180510.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201806_20180920.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201805_20180713.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201804_20180611.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201802_20180417.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201807_20180925.1\n",
      "Reading... /home/puig/Fitxers de Medidas/CNMC_TOTALYEAR/BINEFAR/CLMAGS/CLMAG_0291_201810_20181212.1\n",
      "Ha acabat validacio\n",
      "Tarifa no te totes les hores: 3.0\n",
      "Ha acabat validacio\n"
     ]
    }
   ],
   "source": [
    "def read_CLMAG(path):\n",
    "    #positions = [x for x in xrange(11, 107, 4)]\n",
    "    positions = [x for x in xrange(11, 110, 4)]\n",
    "    hours_map = {\n",
    "        11: '01', 15: '02', 19: '03', 23: '04', 27: '05', 31: '06', 35: '07', 39: '08', 43: '09', 47: '10', \n",
    "        51: '11', 55: '12', 59: '13', 63: '14', 67: '15', 71: '16', 75: '17', 79: '18', 83: '19', 87: '20', \n",
    "        91: '21', 95: '22', 99: '23', 103: '24', 107: '25'\n",
    "    }\n",
    "    R1_code = ';R1;'\n",
    "    consumptions_clmag = []\n",
    "\n",
    "    lines = []\n",
    "    with open(path, 'r') as filename:\n",
    "        for line in filename:\n",
    "            # zfills month / distri / comer / type\n",
    "            a = line.split(';')\n",
    "            a[1] = a[1].zfill(2)\n",
    "            a[3] = a[3].zfill(4)\n",
    "            a[4] = a[4].zfill(4)\n",
    "            a[9] = a[9].zfill(2)\n",
    "            lines.append(str(';'.join(a)))\n",
    "    clmag_aggs = [agg[11:35] for agg in lines]\n",
    "    df_aggs = pd.DataFrame(data=clmag_aggs).drop_duplicates()\n",
    "    clmag_aggs = [x[0] for x in df_aggs.values.tolist()]\n",
    "    aggregation_dict = dict.fromkeys(cols.CLMAG_COLS)\n",
    "    report_map = {}\n",
    "    for x in lines:\n",
    "        if R1_code not in x:\n",
    "            # Get aggregation and date\n",
    "            timestamp_base = '/'.join([x[6:10], x[3:5], x[:2]])\n",
    "            consumption_tmp = x.split(';')\n",
    "            aggregation = x[11:35]\n",
    "            \n",
    "            # Initialize set\n",
    "            if aggregation not in report_map:\n",
    "                report_map[aggregation] = []\n",
    "\n",
    "            # Set timestamp-measure\n",
    "            for pos in positions:\n",
    "                timestamp = '{} {}:00'.format(timestamp_base, hours_map[pos])\n",
    "                if timestamp.find(\" 25:00\") != -1 and timestamp != \"2018/10/28 25:00\":\n",
    "                    continue\n",
    "                report_map[aggregation].append({'timestamp': timestamp, 'measure': int(consumption_tmp[pos])})\n",
    "    return report_map\n",
    "\n",
    "\n",
    "# Llegim els CLMAGS\n",
    "df = pd.DataFrame(data={})\n",
    "base_path = '{}{}/'.format(PATH, 'CLMAGS')\n",
    "for _file in os.listdir(base_path):\n",
    "    path_clmag = base_path + _file\n",
    "    print('Reading... {}'.format(path_clmag))\n",
    "    \n",
    "    rp = read_CLMAG(path_clmag)\n",
    "    data = []\n",
    "    for k, v in rp.iteritems():\n",
    "        aggregation = dict(zip(['distri', 'comer', 'provincia', 'tensio', 'agree_tarifa', 'dh', 'tipo'], tuple(k.split(';'))))\n",
    "        for s in v:\n",
    "            _agg = aggregation.copy()\n",
    "            _agg['timestamp'] = s['timestamp']\n",
    "            _agg['measure'] = s['measure']\n",
    "            data.append(_agg)\n",
    "    df_tmp = pd.DataFrame(data=data)\n",
    "    if df.empty:\n",
    "        df = df_tmp\n",
    "    else:\n",
    "        df = df.append(df_tmp)\n",
    "# Vestim el dataframe\n",
    "for key in ('tipo', 'distribuidora'):\n",
    "    df['tipo'] = df['tipo'].apply(lambda x: x.zfill(2))\n",
    "df_2tariff = df.groupby(['agree_tarifa', 'dh', 'timestamp']).aggregate({'measure': 'sum'}).reset_index()\n",
    "df_2tariff.sort_values(['timestamp', 'agree_tarifa'])\n",
    "\n",
    "# Drop hour change march hour\n",
    "df_2tariff = df_2tariff.drop(df_2tariff[df_2tariff.timestamp == '2018/03/25 03:00'].index)\n",
    "df_2tariff = df_2tariff.sort_values(['timestamp'])\n",
    "\n",
    "# Escrivim els fitxers, un per tarifa\n",
    "df_2tariff = df_2tariff.replace('30', '3.0')\n",
    "df_2tariff = df_2tariff.replace('31', '3.1')\n",
    "df_2tariff['agree_tarifa'] = np.where(\n",
    "    ((df_2tariff['agree_tarifa'] == '3.1') & (df_2tariff['dh'] == 'EB')), \n",
    "    df_2tariff['agree_tarifa'] + ' 30 a 36kV', \n",
    "    df_2tariff['agree_tarifa']\n",
    ")\n",
    "\n",
    "tariffs = list(set(df_2tariff.agree_tarifa))\n",
    "for tariff in tariffs:\n",
    "    df_tariff = df_2tariff[df_2tariff.agree_tarifa == tariff]\n",
    "    # Write file\n",
    "    df_tariff.to_csv('{}result/{}.csv'.format(PATH, tariff), columns=['timestamp', 'measure'], sep=';', index=None)\n",
    "    val_clmag(8760, df_tariff)\n",
    "    write_excel(df_tariff, tariff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ha acabat validacio 61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={})\n",
    "base_path = '{}{}/'.format(PATH, 'F1S')\n",
    "for _file in os.listdir(base_path):\n",
    "    path_f1 = base_path + _file\n",
    "    df_tmp = parser.read_F1(path_f1)\n",
    "    if df.empty:\n",
    "        df = df_tmp\n",
    "    else:\n",
    "        df = df.append(df_tmp)\n",
    "        \n",
    "df_2tariff = df.groupby(['timestamp', 'estacio']).aggregate({'measure': 'sum'}).reset_index()\n",
    "df_2tariff['agree_tarifa'] = '61'\n",
    "df_2tariff = df_2tariff.sort_values(['timestamp'])\n",
    "if val_f1(8760, df_2tariff):\n",
    "    df_2tariff.to_csv('{}result/{}.csv'.format(PATH, '61'), columns=['timestamp', 'measure'], sep=';', index=None)\n",
    "write_excel(df_2tariff, '61')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_0291_20180813_20180814.0\n",
      "F1_0291_20180818_20180819.0\n",
      "F1_0291_20180924_20180925.0\n",
      "F1_0291_20181004_20181005.0\n",
      "F1_0291_20181024_20181029.1\n",
      "F1_0291_20181025_20181029.1\n",
      "F1_0291_20181026_20181029.1\n",
      "F1_0291_20181027_20181029.1\n",
      "F1_0291_20181028_20181029.1\n",
      "F1_0291_20181028_20181029.2\n"
     ]
    }
   ],
   "source": [
    "extract_only_last_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
